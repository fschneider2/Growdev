{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos arquivos "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tendo como uma das tarefas eliminar as imagens que não possuem roda, criei o código abaixo. \n",
    "## - Defino o caminho do diretorio de anotações e de imagens. \n",
    "## - Utilizo a biblioteca os, para navegar até o diretorio, pegar o nome de todos os arquivos e ordenalos em ordem crescente. \n",
    "## - Percorro cada um dos arquivos, abro ele com a função open da biblioteca os, verifico se em seu conteudo existe uma linha que começa com a str \"0\", se sim, salvo o nome do arquivo na lista nomes_ants_com_rodas.\n",
    "## - Por fim, percorro cada posição da lista de anotações, altero o .txt para .jpg, e salvo na lista nomes_imgs_com_rodas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_anotacoes = 'data-20230312T190552Z-001/data/annotations'\n",
    "dir_imagens = 'data-20230312T190552Z-001/data/images/'\n",
    "\n",
    "arquivos = sorted(os.listdir(dir_anotacoes))\n",
    "\n",
    "nomes_ants_com_rodas = []\n",
    "nomes_imgs_com_rodas = []\n",
    "\n",
    "for nome_arquivo in arquivos:\n",
    "\n",
    "    with open(os.path.join(dir_anotacoes, nome_arquivo), 'r') as arquivo:\n",
    "        conteudo = arquivo.read()\n",
    "        padrao = r'\\b0(?![\\d.])'\n",
    "        \n",
    "        if re.search(padrao, conteudo):\n",
    "            nomes_ants_com_rodas.append(nome_arquivo)\n",
    "\n",
    "for nome in nomes_ants_com_rodas:\n",
    "    nome_img = nome.replace('.txt', '.jpg')\n",
    "    nomes_imgs_com_rodas.append(nome_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Percorro a lista de anotações e salvo as bbox posição 1,2,3,4 em uma lista, criando uma lista de listas chamada bboxes.\n",
    "## - Altero o tipo de cada posição para float.\n",
    "## - Por fim crio o y como um array numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = []\n",
    "\n",
    "for nome_arquivo in nomes_ants_com_rodas:\n",
    "\n",
    "    with open(os.path.join(dir_anotacoes, nome_arquivo), 'r') as arquivo:\n",
    "\n",
    "        for linha in arquivo:\n",
    "            \n",
    "            if re.match(r'^0', linha):\n",
    "                dados = linha.strip().split()\n",
    "                bboxes.append(dados[1:])\n",
    "\n",
    "for bbox in bboxes:\n",
    "    for posicao in range(len(bbox)):\n",
    "        bbox[posicao] = float(bbox[posicao])\n",
    "\n",
    "y = np.array(bboxes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Percorro o diretorio de imagens, abrindo cada uma com o cv2, aletrando para preto e branco e normalizando os dados das imagens para 0,1, salvando as informações em uma lista de imagens.\n",
    "\n",
    "## - Percorro a lista de imagens, alterando o tamanho de cada imagem pela metade, salvo a informação em uma lista de mesmo tamanho. \n",
    "\n",
    "## - Foi necessário redmencionar, pois meus testes apresentaram melhor resultado ao usar mais imagens, em vez de imagens de maior tamanho, e com o intuito de balancear a rede conforme a capacidade de meu computador, optei por reduzir as imagens a metade de seu tamanho original. \n",
    "\n",
    "## - Crio o x como uma array numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens = [cv2.imread(dir_imagens + nome, 0) / 255 for nome in nomes_imgs_com_rodas]\n",
    "\n",
    "imagens = [cv2.resize(img, (320, 160)) for img in imagens]\n",
    "\n",
    "x = np.array(imagens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Crio uma função para conseguir plotar um retangulo com as informações YOLO disponiveis no bbox, ela recebe a quantidade de imagens que quero mostrar, o as imagens(x) e os bbox(y), defino que a imagem a ser mostrada é que esta em x na posição i, e que meus pontos para o retangulo são os que estão em y na posição i. Faço o calculo para ter os 4 pontos e atribuo cada um deles em uma variavel, que já esta ajustada com a altura e largura correta. Crio minha img com o cv2 e a função rectangle, que ira mostrar a imagem, o retangulo definido pelos 4 pontos, em co preta(0), e com linha de espessura 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imagens(quantidade, x, y):\n",
    "    \n",
    "    l, a, _ = x[0].shape\n",
    "    for i in range(quantidade):\n",
    "        imagem = x[i]\n",
    "        x_norm, y_norm, w_norm, h_norm = y[i]\n",
    "        x_ = int((x_norm - w_norm / 2) * a)\n",
    "        y_ = int((y_norm + h_norm / 2) * l)\n",
    "        w_ = int((x_norm + w_norm/2) * a)\n",
    "        h_ = int((y_norm - h_norm/2) * l)\n",
    "        img = cv2.rectangle(imagem, (x_, y_), (w_, h_), 0, 4)\n",
    "        cv2.imshow(f'imagem{i}', img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Defino meu x e y de treino e teste, pegando 20% da amostra para teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train , y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apresento o shape, como exigencia da rede, adiciono uma nova camada ao array numpay e apresento novamente o shape ajustado.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 160, 320)\n",
      "(576, 4)\n",
      "(144, 160, 320)\n",
      "(144, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = x_train.shape\n",
    "xTest = x_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (xTrain[0],xTrain[1],xTrain[2], 1))\n",
    "x_test = np.reshape(x_test, (xTest[0],xTest[1], xTest[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 160, 320, 1)\n",
      "(576, 4)\n",
      "(144, 160, 320, 1)\n",
      "(144, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Apresento imagens que serão utilizadas para treinar, defini como 10, mas alterando o número, irá mostrar a quantidade que você definir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_imagens(10, x_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Fiz varios testes, com mais e com menos kernels e neuronios, 32, 16 e 64 se mostraram eficientes e com consumo adequado de memoria e processamento. \n",
    "## - Crio uma rede sequencial, com duas camadas de convolução sequidas de camadas maxPooling. Utilizo uma cada flatten para ajustar as imagens de forma que possam seguir para uma camada densa de 64 neuronios e por fim uma camada de saida com 4 neuronios, onde cada um representa a saida de um dos pontos que irão tentar identificar onde esta a roda do carro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(4, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - utilizo o calculo mse para definir o loss e uso o 'mae' como metrica, por ser um problema de regressão e quanto menor for essa metrica, mais próximo a rede esta de encontrar o valor verdadeiro a ser previsto.\n",
    "## - A rede é treinada em 50 epocas, utilizando um batch_size adequado a capacidade de processamento e memoria disponivel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "48/48 [==============================] - 17s 342ms/step - loss: 0.0260 - mae: 0.1076\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 17s 348ms/step - loss: 0.0057 - mae: 0.0493\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 17s 348ms/step - loss: 0.0026 - mae: 0.0348\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 17s 348ms/step - loss: 0.0014 - mae: 0.0267\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 17s 347ms/step - loss: 8.8211e-04 - mae: 0.0212\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 17s 348ms/step - loss: 5.8082e-04 - mae: 0.0175\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 17s 351ms/step - loss: 4.2441e-04 - mae: 0.0149\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 17s 351ms/step - loss: 3.5288e-04 - mae: 0.0140\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 17s 350ms/step - loss: 3.0086e-04 - mae: 0.0131\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 17s 352ms/step - loss: 2.4850e-04 - mae: 0.0115\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 17s 351ms/step - loss: 2.4318e-04 - mae: 0.0110\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 2.4186e-04 - mae: 0.0113\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 17s 352ms/step - loss: 2.3105e-04 - mae: 0.0111\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 1.5960e-04 - mae: 0.0093\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 17s 352ms/step - loss: 1.4815e-04 - mae: 0.0091\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 1.4449e-04 - mae: 0.0088\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 17s 353ms/step - loss: 1.4744e-04 - mae: 0.0089\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 17s 356ms/step - loss: 1.3754e-04 - mae: 0.0085\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 17s 362ms/step - loss: 1.0824e-04 - mae: 0.0076\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 18s 365ms/step - loss: 1.0211e-04 - mae: 0.0073\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 18s 366ms/step - loss: 1.3958e-04 - mae: 0.0088\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 18s 367ms/step - loss: 1.3996e-04 - mae: 0.0087\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 18s 365ms/step - loss: 1.5397e-04 - mae: 0.0092\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 18s 367ms/step - loss: 1.4871e-04 - mae: 0.0088\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 18s 366ms/step - loss: 1.3221e-04 - mae: 0.0084\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 18s 366ms/step - loss: 1.4414e-04 - mae: 0.0088\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 17s 360ms/step - loss: 1.4558e-04 - mae: 0.0090\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 17s 361ms/step - loss: 1.2975e-04 - mae: 0.0085\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 17s 359ms/step - loss: 1.1761e-04 - mae: 0.0081\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 17s 362ms/step - loss: 1.1120e-04 - mae: 0.0076\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 17s 361ms/step - loss: 1.1669e-04 - mae: 0.0080\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 17s 360ms/step - loss: 1.1951e-04 - mae: 0.0081\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 17s 361ms/step - loss: 1.4690e-04 - mae: 0.0092\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 17s 360ms/step - loss: 1.3697e-04 - mae: 0.0089\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 17s 362ms/step - loss: 1.2502e-04 - mae: 0.0083\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 17s 360ms/step - loss: 1.0030e-04 - mae: 0.0074\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 17s 362ms/step - loss: 7.3643e-05 - mae: 0.0065\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 17s 359ms/step - loss: 7.3780e-05 - mae: 0.0064\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 17s 361ms/step - loss: 7.8525e-05 - mae: 0.0066\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 17s 362ms/step - loss: 8.6624e-05 - mae: 0.0071\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 17s 360ms/step - loss: 6.5729e-05 - mae: 0.0060\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 17s 362ms/step - loss: 6.2025e-05 - mae: 0.0059\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 17s 360ms/step - loss: 7.0283e-05 - mae: 0.0063\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 17s 362ms/step - loss: 8.3371e-05 - mae: 0.0068\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 17s 361ms/step - loss: 9.5568e-05 - mae: 0.0073\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 17s 362ms/step - loss: 9.4820e-05 - mae: 0.0072\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 17s 362ms/step - loss: 1.2049e-04 - mae: 0.0082\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 17s 362ms/step - loss: 1.3110e-04 - mae: 0.0085\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 17s 361ms/step - loss: 1.5093e-04 - mae: 0.0092\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 17s 361ms/step - loss: 1.4055e-04 - mae: 0.0086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5d0b4ba90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 50, batch_size = 12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Realizado o teste, e apresentado o resultado, Se mantido 'len(x_teste)' como quantidade de imagens a serem apresentadas, todas as 144 serão exibidas, caso queira exibir menos, mude este valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 146ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_imagens(len(x_test), x_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
